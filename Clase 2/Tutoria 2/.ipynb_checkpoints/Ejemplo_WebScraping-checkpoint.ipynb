{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de WebScraping con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener S&P Merval que es el principal índice del Mercado de Valores de Buenos Aires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:53:23.662759Z",
     "start_time": "2019-01-27T17:53:23.651938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías Python que utilizaremos\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:38:57.659158Z",
     "start_time": "2019-01-27T17:38:57.655785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Indicamos la ruta de la web que deseamos acceder\n",
    "url_page = 'https://bolsar.info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:40:11.127856Z",
     "start_time": "2019-01-27T17:40:10.642601Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmirabete/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bolsar.info'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de Mercado - BCBA\n"
     ]
    }
   ],
   "source": [
    "# Y ahora haremos el request a esa ruta y procesaremos el HTML mediante un objeto de tipo BeautifulSoap. \n",
    "# Utilizando lxml como analizador.\n",
    "\n",
    "#page = requests.get(url_page).text \n",
    "page = requests.get(url_page, verify=False).text \n",
    "\n",
    "# Verificar si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    # Por ejemplo, puedes imprimir el título de la página:\n",
    "    print(soup.title.text)\n",
    "\n",
    "    #print(soup)\n",
    "else:\n",
    "    print(\"No se pudo acceder a la página web.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ahora nos toca pensar la estrategia para acceder al valor. En nuestro caso nos interesa primero acceder a la tabla, y de allí a sus celdas. Por suerte la tabla tiene un id único!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:42:00.515429Z",
     "start_time": "2019-01-27T17:42:00.504178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"tbAlzasBajasSinCambio\" style=\"font-size: 17px;\" width=\"100%\">\n",
      "<tbody>\n",
      "</tbody></table>\n"
     ]
    }
   ],
   "source": [
    "# Buscar el elemento <table> con el atributo 'id' igual a 'tbAlzasBajasSinCambio'\n",
    "tabla = soup.find('table', attrs={'id':'tbAlzasBajasSinCambio'})\n",
    "\n",
    "# Verificar si se encontró la tabla\n",
    "if tabla:\n",
    "    # Realizar acciones en la tabla encontrada\n",
    "    print(tabla)\n",
    "else:\n",
    "    print(\"La tabla no fue encontrada en la página.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos devuelve el `<tbody>` vacío y la información que deseamos está dentro de este `<tbody>`generado dinámicamente a través de JavaScript, `BeautifulSoup`, por sí solo, no puede capturar esa información, ya que se trata de una técnica conocida como carga dinámica de contenido.\n",
    "\n",
    "Para capturar datos generados dinámicamente a través de JavaScript, es posible que necesitmos una herramienta adicional como `Selenium`, que puede controlar un navegador web y ejecutar JavaScript. Aquí hay un ejemplo de cómo usar Selenium con Chrome WebDriver para obtener la página y luego extraer la información de la tabla:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, debes instalar `Selenium` si aún no lo hemos hecho:\n",
    "\n",
    "    $ pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"tbAlzasBajasSinCambio\" style=\"font-size: 17px;\" width=\"100%\"><tbody><tr class=\"filaFiltroPanelPrincipal 3\" style=\"border-top: 2px solid #ccc;\">\n",
      "<td class=\"nombreItemFila\">Indice</td><td class=\"nombreItemFila\" style=\"text-align:right\">Valor</td><td class=\"nombreItemFila\" style=\"text-align:right;\">Variación</td></tr><tr class=\"filaFiltroPanelPrincipal 3\" style=\"border-top: 2px solid #ccc;\">\n",
      "<td class=\"nombreItemFila\"><a href=\"indices.php?indice=0\">S&amp;P BOLSA-G</a></td><td class=\"nombreItemFila\" style=\"text-align:right\">26.903.047,89</td><td class=\"nombreItemFila\" style=\"text-align:right;color:#e94b46\">-2,41% <i class=\"fa fa-arrow-down\" style=\"color:#e94b46;\"></i></td></tr><tr class=\"filaFiltroPanelPrincipal 3\" style=\"border-top: 2px solid #ccc;\">\n",
      "<td class=\"nombreItemFila\"><a href=\"indices.php?indice=2\">S&amp;P MERVAL</a></td><td class=\"nombreItemFila\" style=\"text-align:right\">635.969,46</td><td class=\"nombreItemFila\" style=\"text-align:right;color:#e94b46\">-2,69% <i class=\"fa fa-arrow-down\" style=\"color:#e94b46;\"></i></td></tr></tbody></table>\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Opciones para el navegador Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Ejecutar Chrome en modo sin cabeza (sin interfaz gráfica)\n",
    "\n",
    "# Inicializar el controlador de Chrome\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Acceder a la página web con Selenium\n",
    "driver.get(url_page)\n",
    "\n",
    "# Esperar a que la página se cargue completamente (puedes ajustar este tiempo según sea necesario)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Obtener el contenido HTML de la página después de que JavaScript haya cargado los datos\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Cerrar el navegador web controlado por Selenium\n",
    "driver.quit()\n",
    "\n",
    "# Analizar el contenido HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Buscar la tabla dentro del HTML cargado dinámicamente\n",
    "tabla = soup.find('table', id='tbAlzasBajasSinCambio')\n",
    "\n",
    "# Verificar si se encontró la tabla\n",
    "if tabla:\n",
    "    # Realizar acciones en la tabla encontrada\n",
    "    print(tabla)\n",
    "else:\n",
    "    print(\"La tabla no fue encontrada en la página.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:55:08.443093Z",
     "start_time": "2019-01-27T17:55:08.436365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice: \n",
      "Valor: \n"
     ]
    }
   ],
   "source": [
    "indice=\"\"\n",
    "valor=\"\"\n",
    "nroFila=0\n",
    "for fila in tabla.find_all(\"tr\"):\n",
    "    if nroFila==1:\n",
    "        nroCelda=0\n",
    "        for celda in fila.find_all('td'):\n",
    "            if nroCelda==0:\n",
    "                name=celda.text\n",
    "                print(\"Indice:\", indice)\n",
    "            if nroCelda==2:\n",
    "                price=celda.text\n",
    "                print(\"Valor:\", valor)\n",
    "            nroCelda=nroCelda+1\n",
    "    nroFila=nroFila+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice\n",
      "Valor\n",
      "Variación\n",
      "S&P BOLSA-G\n",
      "26.903.047,89\n",
      "-2,41%\n",
      "S&P MERVAL\n",
      "635.969,46\n",
      "-2,69%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener todas las filas de la tabla\n",
    "filas = tabla.find_all('tr')\n",
    "    \n",
    "# Recorrer las filas y obtener los valores de las celdas\n",
    "for fila in filas:\n",
    "    # Obtener todas las celdas de la fila\n",
    "    celdas = fila.find_all('td')\n",
    "        \n",
    "    # Imprimir los valores de las celdas\n",
    "    for celda in celdas:\n",
    "        print(celda.text.strip())  # Utiliza strip() para eliminar espacios en blanco alrededor de los valores\n",
    "print()  # Agregar una línea en blanco entre las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice\n",
      "Valor\n",
      "Variación\n",
      "\n",
      "S&P BOLSA-G\n",
      "26.946.950,65\n",
      "-2,25%\n",
      "\n",
      "S&P MERVAL\n",
      "636.932,70\n",
      "-2,55%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML de la tabla\n",
    "html = \"\"\"\n",
    "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" id=\"tbAlzasBajasSinCambio\" style=\"font-size: 17px;\" width=\"100%\">\n",
    "    <tbody>\n",
    "        <tr class=\"filaFiltroPanelPrincipal 3\" style=\"border-top: 2px solid #ccc;\">\n",
    "            <td class=\"nombreItemFila\">Indice</td>\n",
    "            <td class=\"nombreItemFila\" style=\"text-align:right\">Valor</td>\n",
    "            <td class=\"nombreItemFila\" style=\"text-align:right;\">Variación</td>\n",
    "        </tr>\n",
    "        <tr class=\"filaFiltroPanelPrincipal 3\" style=\"border-top: 2px solid #ccc;\">\n",
    "            <td class=\"nombreItemFila\"><a href=\"indices.php?indice=0\">S&amp;P BOLSA-G</a></td>\n",
    "            <td class=\"nombreItemFila\" style=\"text-align:right\">26.946.950,65</td>\n",
    "            <td class=\"nombreItemFila\" style=\"text-align:right;color:#e94b46\">-2,25% <i class=\"fa fa-arrow-down\" style=\"color:#e94b46;\"></i></td>\n",
    "        </tr>\n",
    "        <tr class=\"filaFiltroPanelPrincipal 3\" style=\"border-top: 2px solid #ccc;\">\n",
    "            <td class=\"nombreItemFila\"><a href=\"indices.php?indice=2\">S&amp;P MERVAL</a></td>\n",
    "            <td class=\"nombreItemFila\" style=\"text-align:right\">636.932,70</td>\n",
    "            <td class=\"nombreItemFila\" style=\"text-align:right;color:#e94b46\">-2,55% <i class=\"fa fa-arrow-down\" style=\"color:#e94b46;\"></i></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "# Analizar el contenido HTML\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Encontrar la tabla por su ID\n",
    "tabla = soup.find('table', id='tbAlzasBajasSinCambio')\n",
    "\n",
    "# Verificar si se encontró la tabla\n",
    "if tabla:\n",
    "    # Obtener todas las filas de la tabla\n",
    "    filas = tabla.find_all('tr')\n",
    "    \n",
    "    # Recorrer las filas y obtener los valores de las celdas\n",
    "    for fila in filas:\n",
    "        # Obtener todas las celdas de la fila\n",
    "        celdas = fila.find_all('td')\n",
    "        \n",
    "        # Imprimir los valores de las celdas\n",
    "        for celda in celdas:\n",
    "            print(celda.text.strip())  # Utiliza strip() para eliminar espacios en blanco alrededor de los valores\n",
    "        print()  # Agregar una línea en blanco entre las filas\n",
    "else:\n",
    "    print(\"La tabla no fue encontrada en el HTML.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:56:28.279786Z",
     "start_time": "2019-01-27T17:56:28.271938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Abrimos el csv con append para que pueda agregar contenidos al final del archivo\n",
    "with open('bolsa_ibex35.csv', 'a') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([name, price, datetime.now()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener resultados de Futbol\n",
    "## Ejemplo Liga BBVA - España - Primera -  desde marcadores.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T18:26:04.881325Z",
     "start_time": "2019-01-27T18:26:04.877803Z"
    }
   },
   "outputs": [],
   "source": [
    "url_page = 'https://www.marcadores.com/futbol/espana/liga-bbva/?competitionRoundId=486942' # jornada 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T18:26:07.064454Z",
     "start_time": "2019-01-27T18:26:05.493551Z"
    }
   },
   "outputs": [],
   "source": [
    "# tarda 1500 milisegundos\n",
    "page = requests.get(url_page).text \n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T18:31:00.402982Z",
     "start_time": "2019-01-27T18:31:00.299063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos la tabla por un ID específico\n",
    "tabla = soup.find('table', attrs={'class': 'matches'})\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T18:33:29.634584Z",
     "start_time": "2019-01-27T18:33:29.621584Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "equipo1=\"\"\n",
    "equipo2=\"\"\n",
    "resultado=\"\"\n",
    "nroFila=0\n",
    "for fila in tabla.find_all(\"tr\"):\n",
    "    if nroFila>0:\n",
    "        nroCelda=0\n",
    "        capturar=False\n",
    "        for celda in fila.find_all('td'):\n",
    "            if nroCelda==1 and celda.text=='Fin.':\n",
    "                capturar=True\n",
    "            if capturar and nroCelda==2:\n",
    "                equipo1=celda.text\n",
    "            if capturar and nroCelda==4:\n",
    "                equipo2=celda.text\n",
    "            if capturar and nroCelda==5:\n",
    "                resultado=celda.text\n",
    "                print(\"Partido:\", equipo1,'vs',equipo2,resultado)\n",
    "                data.append((equipo1,equipo2,resultado))\n",
    "            nroCelda=nroCelda+1\n",
    "    nroFila=nroFila+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T18:34:52.245736Z",
     "start_time": "2019-01-27T18:34:52.233185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Abrimos el csv con append para que pueda agregar contenidos al final del archivo\n",
    "with open('partidos_liga_primera.csv', 'a') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for equipo1, equipo2,resultado in data:\n",
    "        writer.writerow([equipo1, equipo2, resultado,datetime.now()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otros ejemplos de WebScaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:37.428233Z",
     "start_time": "2019-01-28T18:12:37.420625Z"
    }
   },
   "outputs": [],
   "source": [
    "#supongamos tenemos el siguiente HTML\n",
    "pagina_web = \"<html>\" \\\n",
    "            + \"<head></head>\" \\\n",
    "            + \"<body>\" \\\n",
    "                + \"<div class='contenedor'>\" \\\n",
    "                    + \"<div id='123' name='bloque_bienvenida' class='verde'>\" \\\n",
    "                        + \"Bienvenido a mi web\" \\\n",
    "                    + \"</div>\" \\\n",
    "                + \"</div>\" \\\n",
    "            + \"</body>\" \\\n",
    "            + \"</html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:38.100550Z",
     "start_time": "2019-01-28T18:12:38.096154Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(pagina_web, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:38.677469Z",
     "start_time": "2019-01-28T18:12:38.670578Z"
    }
   },
   "outputs": [],
   "source": [
    "#Obtener por ID:\n",
    "elTexto = soup.find('div', attrs={'id': '123'}).getText()\n",
    "print(elTexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:39.718413Z",
     "start_time": "2019-01-28T18:12:39.712544Z"
    }
   },
   "outputs": [],
   "source": [
    "#Obtener por Clase CSS:\n",
    "elTexto = soup.find('div', attrs={'class': 'verde'}).getText()\n",
    "print(elTexto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:40.673362Z",
     "start_time": "2019-01-28T18:12:40.667391Z"
    }
   },
   "outputs": [],
   "source": [
    "#Obtener dentro de otra etiqueta anidado:\n",
    "elTexto = next(soup.div.children).getText() #con next obtiene primer \"hijo\"\n",
    "print(elTexto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener items de un listado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:42.573969Z",
     "start_time": "2019-01-28T18:12:42.567849Z"
    }
   },
   "outputs": [],
   "source": [
    "#supongamos tenemos el siguiente HTML\n",
    "pagina_web = \"<html>\" \\\n",
    "    + \"<head></head>\" \\\n",
    "    + \"<body>\" \\\n",
    "        + \"<div class='contenedor'>\" \\\n",
    "            + \"<ul>\" \\\n",
    "                + \"<li>Perro</li>\" \\\n",
    "                + \"<li>Gato</li>\" \\\n",
    "                + \"<li>Tortuga</li>\" \\\n",
    "            + \"</ul>\" \\\n",
    "        + \"</div>\" \\\n",
    "    + \"</body>\" \\\n",
    "    + \"</html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:43.383058Z",
     "start_time": "2019-01-28T18:12:43.378520Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(pagina_web, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:44.100260Z",
     "start_time": "2019-01-28T18:12:44.094916Z"
    }
   },
   "outputs": [],
   "source": [
    "for child in soup.ul.children:\n",
    "    print(child.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T18:12:44.972925Z",
     "start_time": "2019-01-28T18:12:44.967460Z"
    }
   },
   "outputs": [],
   "source": [
    "items = soup.find_all('li')\n",
    "for item in items:\n",
    "    print(item.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener Enlaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T09:25:01.595660Z",
     "start_time": "2019-01-29T09:25:01.576485Z"
    }
   },
   "outputs": [],
   "source": [
    "#supongamos tenemos el siguiente HTML\n",
    "pagina_web = \"<html>\" \\\n",
    "    + \"<head></head>\" \\\n",
    "    + \"<body>\" \\\n",
    "        + \"<div class='contenedor'>\" \\\n",
    "            + \"<ul>\" \\\n",
    "                + \"<li><a href='http://www.google.com'>Google</a></li>\" \\\n",
    "                + \"<li><a href='http://www.yahoo.com'>Yahoo</a></li>\" \\\n",
    "                + \"<li><a href='http://www.bing.com'>Bing</a></li>\" \\\n",
    "            + \"</ul>\" \\\n",
    "        + \"</div>\" \\\n",
    "    + \"</body>\" \\\n",
    "    + \"</html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T09:25:04.281499Z",
     "start_time": "2019-01-29T09:25:04.250643Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(pagina_web, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T09:25:43.006626Z",
     "start_time": "2019-01-29T09:25:42.996092Z"
    }
   },
   "outputs": [],
   "source": [
    "items = soup.find_all('a')\n",
    "for item in items:\n",
    "    print(item['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo completo Extraer enlaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T09:37:57.684739Z",
     "start_time": "2019-01-29T09:37:57.069538Z"
    }
   },
   "outputs": [],
   "source": [
    "url_page = 'https://www.lifeder.com/cientificos-famosos/'\n",
    "page = requests.get(url_page).text \n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "contenido = soup.find('div', attrs={'class': 'td-post-content'})\n",
    "items = contenido.find_all('a')\n",
    "for item in items:\n",
    "    print(item['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El artículo completo en www.aprendemachinelearning.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
