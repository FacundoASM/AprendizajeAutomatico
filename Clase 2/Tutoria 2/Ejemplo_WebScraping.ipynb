{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de WebScraping con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener S&P Merval que es el principal índice del Mercado de Valores de Buenos Aires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:53:23.662759Z",
     "start_time": "2019-01-27T17:53:23.651938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías Python que utilizaremos\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:38:57.659158Z",
     "start_time": "2019-01-27T17:38:57.655785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Indicamos la ruta de la web que deseamos acceder\n",
    "url_page = 'https://bolsar.info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:40:11.127856Z",
     "start_time": "2019-01-27T17:40:10.642601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y ahora haremos el request a esa ruta y procesaremos el HTML mediante un objeto de tipo BeautifulSoap. \n",
    "\n",
    "#page = requests.get(url_page).text \n",
    "page = requests.get(url_page, verify=False)\n",
    "\n",
    "# Verificar si la solicitud fue exitosa\n",
    "if page.status_code == 200:\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    # Por ejemplo, puedes imprimir el título de la página:\n",
    "    print(soup.title.text)\n",
    "\n",
    "    #print(soup)\n",
    "else:\n",
    "    print(\"No se pudo acceder a la página web.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ahora nos toca pensar la estrategia para acceder al valor. En nuestro caso nos interesa primero acceder a la tabla, y de allí a sus celdas. Por suerte la tabla tiene un id único!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:42:00.515429Z",
     "start_time": "2019-01-27T17:42:00.504178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Buscar el elemento <table> con el atributo 'id' igual a 'tbAlzasBajasSinCambio'\n",
    "tabla = soup.find('table', attrs={'id':'tbAlzasBajasSinCambio'})\n",
    "\n",
    "# Verificar si se encontró la tabla\n",
    "if tabla:\n",
    "    # Realizar acciones en la tabla encontrada\n",
    "    print(tabla)\n",
    "else:\n",
    "    print(\"La tabla no fue encontrada en la página.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos devuelve el `<tbody>` vacío y la información que deseamos está dentro de este `<tbody>`generado dinámicamente a través de JavaScript, `BeautifulSoup`, por sí solo, no puede capturar esa información, ya que se trata de una técnica conocida como carga dinámica de contenido.\n",
    "\n",
    "Para capturar datos generados dinámicamente a través de JavaScript, es posible que necesitmos una herramienta adicional como `Selenium`, que puede controlar un navegador web y ejecutar JavaScript. Aquí hay un ejemplo de cómo usar Selenium con Chrome WebDriver para obtener la página y luego extraer la información de la tabla:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, debes instalar `Selenium` si aún no lo hemos hecho:\n",
    "\n",
    "    $ pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Opciones para el navegador Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Ejecutar Chrome en modo sin cabeza (sin interfaz gráfica)\n",
    "\n",
    "# Inicializar el controlador de Chrome\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Acceder a la página web con Selenium\n",
    "driver.get(url_page)\n",
    "\n",
    "# Esperar a que la página se cargue completamente (puedes ajustar este tiempo según sea necesario)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Obtener el contenido HTML de la página después de que JavaScript haya cargado los datos\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Cerrar el navegador web controlado por Selenium\n",
    "driver.quit()\n",
    "\n",
    "# Analizar el contenido HTML con BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Buscar la tabla dentro del HTML cargado dinámicamente\n",
    "tabla = soup.find('table', id='tbAlzasBajasSinCambio')\n",
    "\n",
    "# Verificar si se encontró la tabla\n",
    "if tabla:\n",
    "    # Realizar acciones en la tabla encontrada\n",
    "    print(tabla)\n",
    "else:\n",
    "    print(\"La tabla no fue encontrada en la página.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todas las filas de la tabla\n",
    "filas = tabla.find_all('tr')\n",
    "    \n",
    "# Recorrer las filas y obtener los valores de las celdas\n",
    "for fila in filas:\n",
    "    # Obtener todas las celdas de la fila\n",
    "    celdas = fila.find_all('td')\n",
    "        \n",
    "    # Imprimir los valores de las celdas\n",
    "    for celda in celdas:\n",
    "        print(celda.text.strip())  # Utiliza strip() para eliminar espacios en blanco alrededor de los valores\n",
    "print()  # Agregar una línea en blanco entre las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar todas las filas de la tabla\n",
    "filas = tabla.find_all('tr')\n",
    "    \n",
    "# Iterar a través de las filas\n",
    "for fila in filas:\n",
    "    # Buscar las celdas de la fila\n",
    "    celdas = fila.find_all('td')\n",
    "        \n",
    "    # Verificar si la fila contiene el índice \"S&P MERVAL\"\n",
    "    if any(\"S&P MERVAL\" in celda.text for celda in celdas):\n",
    "        # Si la fila contiene el índice, almacenar los valores de las celdas en variables\n",
    "        valores_celda = [celda.text.strip() for celda in celdas]\n",
    "            \n",
    "        # Imprimir los valores de las celdas\n",
    "        print(valores_celda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T17:56:28.279786Z",
     "start_time": "2019-01-27T17:56:28.271938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Abrimos el csv con append para que pueda agregar contenidos al final del archivo\n",
    "with open('bolsa_m.csv', 'a') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([valores_celda[0], valores_celda[1], valores_celda[2], datetime.now()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
